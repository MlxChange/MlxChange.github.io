# 1.视频是什么

由于人类眼睛的特殊结构，画面快速切换时，画面会有残留，感觉起来就是连贯的动作。所以，**视频就是由一系列图片构成的**。

##### 视频帧

帧，是视频的一个基本概念，表示一张画面，如上面的翻页动画书中的一页，就是一帧。一个视频就是由许许多多帧组成的

##### 刷新率

屏幕每秒画面被刷新的次数，分为垂直刷新率和水平刷新率，一般我们提到的都是指垂直刷新率，以赫兹(Hz)为单位，刷新率越高，图像就越稳定，图像显示就越自然清晰。

##### 帧率

帧率，即单位时间内帧的数量，单位为：帧/秒 或fps（frames per second）。如动画书中，一秒内包含多少张图片，图片越多，画面越顺滑，过渡越自然。

帧率的一般以下几个典型值：

24/25 fps：1秒 24/25 帧，一般的电影帧率。

30/60 fps：1秒 30/60 帧，游戏的帧率，30帧可以接受，60帧会感觉更加流畅逼真。

85 fps以上人眼基本无法察觉出来了，所以更高的帧率在视频里没有太大意义。

##### 色彩空间

![](/img/Pixel.webp)

这里我们只讲常用到的两种色彩空间。

- RGB

RGB的颜色模式应该是我们最熟悉的一种，在现在的电子设备中应用广泛。通过R G B三种基础色，可以混合出所有的颜色。以RGB24为例，图像像素数据的存储方式如下:

![](/img/pixelLine.webp)

- YUV

这里着重讲一下YUV，这种色彩空间并不是我们熟悉的。这是一种亮度与色度分离的色彩格式。

早期的电视都是黑白的，即只有亮度值，即Y。有了彩色电视以后，加入了UV两种色度，形成现在的YUV，也叫YCbCr。

Y：亮度，就是灰度值。除了表示亮度信号外，还含有较多的绿色通道量。

U：蓝色通道与亮度的差值。

V：红色通道与亮度的差值。

**颜色空间的转换：**
 不同颜色可以通过一定的数学关系相互转换：

> **RGB转YUV：**
>  Y = (0.257 * R) + (0.504 * G) + (0.098 * B) + 16
>  Cr = V = (0.439 * R) - (0.368 * G) - (0.071 * B) + 128
>  Cb = U = -( 0.148 * R) - (0.291 * G) + (0.439 * B) + 128

> **YUV转RGB：**
>  B = 1.164(Y - 16) + 2.018(U - 128)
>  G = 1.164(Y - 16) - 0.813(V - 128) - 0.391(U - 128)
>  R = 1.164(Y - 16) + 1.596(V - 128)

# 2.音频是什么

音频数据的承载方式最常用的是**脉冲编码调制**，即**PCM**。

在自然界中，声音是连续不断的，是一种模拟信号，那怎样才能把声音保存下来呢？那就是把声音数字化，即转换为数字信号。

我们知道声音是一种波，有自己的振幅和频率，那么要保存声音，就要保存声音在各个时间点上的振幅。

![](/img/sound.webp)

而数字信号并不能连续保存所有时间点的振幅，事实上，并不需要保存连续的信号，就可以还原到人耳可接受的声音。所以每隔一个小小的时间间隔，去用尺子量一下这个点的位置在哪里。那么只要这个间隔是一定的,我们就可以把这个曲线描述成：{9,11,12,13,14,14,15,15,15,14,14,13,12,10,9,7...}

<img src="/img/soundWave.webp" style="zoom: 50%;" />

如果我们把这个时间间隔取得更小，拿的尺子越精确，那么测量得到的，用来描述这个曲线的数字也可以做到更加地精确。用专业的术语来说，我们每两次测一下位置的时间间隔，就是所谓的**采样率**。采样率等于多少，就意味着我们每秒钟进行了多少次这样的测量。所谓音质，就是指最后我们描述这个曲线的数字，到底和真实的曲线误差有多大。

根据奈奎斯特采样定理：为了不失真地恢复模拟信号，采样频率应该不小于模拟信号频谱中最高频率的2倍。

根据以上分析，PCM的采集步骤分为以下步骤：

> 模拟信号->**采样->量化->编码-**>数字信号

![](/img/soundStep.webp)

采样的基本定理：为了复原波形，一次振动中，必须有2个点的采样，人耳能够感觉到的最高频率为20kHz，因此要满足人耳的听觉要求，则需要至少每秒进行40k次采样。

##### 采样率和采样位数

采样率，即采样的频率。

上面提到，采样率要大于原声波频率的2倍，人耳能听到的最高频率为20kHz，所以为了满足人耳的听觉要求，采样率至少为40kHz，通常为44.1kHz，更高的通常为48kHz。

采样位数，涉及到上面提到的振幅量化。波形振幅在模拟信号上也是连续的样本值，而在数字信号中，信号一般是不连续的，所以模拟信号量化以后，只能取一个近似的整数值，为了记录这些振幅值，采样器会采用一个固定的位数来记录这些振幅值，通常有8位、16位、32位。

| 位数 | 最小值      | 最大值     |
| ---- | ----------- | ---------- |
| 8    | 0           | 255        |
| 16   | -32768      | 32767      |
| 32   | -2147483648 | 2147483647 |

##### 声道数

声道数，是指支持能**不同发声**（注意是不同声音）的音响的个数。

单声道：1个声道
双声道：2个声道
立体声道：默认为2个声道
立体声道（4声道）：4个声道

##### 码率

码率，是指一个数据流中每秒钟能通过的信息量，单位bps（bit per second）

码率 = 采样率 * 采样位数 * 声道数

# 3.编码

这里的编码和上面音频中提到的编码不是同个概念，而是指**压缩编码**。

我们知道，在计算机的世界中，一切都是0和1组成的，音频和视频数据也不例外。由于音视频的数据量庞大，如果按照裸流数据存储的话，那将需要耗费非常大的存储空间，也不利于传送。而音视频中，其实包含了大量0和1的重复数据，因此可以通过一定的算法来压缩这些0和1的数据。

特别在视频中，由于画面是逐渐过渡的，因此整个视频中，包含了大量画面/像素的重复，这正好提供了非常大的压缩空间。

因此，编码可以大大减小音视频数据的大小，让音视频更容易存储和传送。

### H264编码简介

H264是目前最主流的视频编码标准，所以我们后续的文章中主要以该编码格式为基准。

H264由ITU和MPEG共同定制，属于MPEG-4第十部分内容。

视频是由一帧一帧画面构成的，但是在视频的数据中，并不是真正按照一帧一帧原始数据保存下来的（如果这样，压缩编码就没有意义了）。

H264会根据一段时间内，画面的变化情况，选取一帧画面作为完整编码，下一帧只记录与上一帧完整数据的差别，是一个动态压缩的过程。

在H264中，三种类型的帧数据分别为

**I帧**：帧内编码帧。就是一个完整帧。

**P帧**：前向预测编码帧。是一个非完整帧，通过参考前面的I帧或P帧生成。

**B帧**：双向预测内插编码帧。参考前后图像帧编码生成。B帧依赖其前最近的一个I帧或P帧及其后最近的一个P帧。

#### DTS与PTS

DTS全称：Decoding Time Stamp。标示读入内存中数据流在什么时候开始送入解码器中进行解码。也就是解码顺序的时间戳。

PTS全称：Presentation Time Stamp。用于标示解码后的视频帧什么时候被显示出来。

> 在没有B帧的情况下，DTS和PTS的输出顺序是一样的，一旦存在B帧，PTS和DTS则会不同。

在音频中PTS和DTS一般相同。但是在视频中，由于B帧的存在，PTS和DTS可能会不同。

> 实际帧顺序：I B B P
>
> 存放帧顺序：I P B B
>
> 解码时间戳：1 4 2 3
>
> 展示时间戳：1 2 3 4

#### 帧的色彩空间

前面我们介绍了RGB和YUV两种图像色彩空间。H264采用的是YUV。

YUV存储方式分为两大类：planar 和 packed。

> planar：先存储所有Y，紧接着存储所有U，最后是V；
>  packed：每个像素点的 Y、U、V 连续交叉存储。

planar如下：

![](/img/frame_planar.jpg)

packed:

![](/img/frame_packed.jpg)

由于人眼对色度敏感度低，所以可以通过省略一些色度信息，即亮度共用一些色度信息，进而节省存储空间。因此，planar又区分了以下几种格式： YUV444、 YUV422、YUV420。

YUV 4:4:4采样，每一个Y对应一组UV分量。

<img src="/img/yuv444.jpg" style="zoom:50%;" />

<img src="/img/yuv422.jpg" style="zoom:50%;" />

<img src="/img/yuv420.jpg" style="zoom: 50%;" />

其中，**最常用的就是YUV420**。

### 音频编码

PCM(Pulse Code Modulation)也被称为脉冲编码调制。PCM音频数据是未经压缩的音频采样数据裸流，它是由模拟信号经过采样、量化、编码转换成的标准的数字音频数据。

PCM音频数据是如何存储的

![](/img/pcm_save.png)

一般我们描述PCM音频数据的参数的时候有如下描述方式

```
44100HZ 16bit stereo: 每秒钟有 44100 次采样, 采样数据用 16 位(2字节)记录, 双声道(立体声);
22050HZ 8bit  mono: 每秒钟有 22050 次采样, 采样数据用 8 位(1字节)记录, 单声道;
```

#### AAC编码简介

AAC是新一代的音频有损压缩技术，一种高压缩比的音频压缩算法。在MP4视频中的音频数据，大多数时候都是采用AAC压缩格式。

AAC格式主要分为两种：ADIF、ADTS。

**ADIF**：Audio Data Interchange Format。 音频数据交换格式。这种格式的特征是可以确定的找到这个音频数据的开始，不需进行在音频数据流中间开始的解码，即它的解码必须在明确定义的开始处进行。这种格式常用在磁盘文件中。

**ADTS**：Audio Data Transport Stream。 音频数据传输流。这种格式的特征是它是一个有同步字的比特流，解码可以在这个流中任何位置开始。它的特征类似于mp3数据流格式。

> ADTS可以在任意帧解码，它每一帧都有头信息。ADIF只有一个统一的头，所以必须得到所有的数据后解码。且这两种的header的格式也是不同的，目前一般编码后的都是ADTS格式的音频流。

ADIF数据格式：

| header | raw_data |
| ------ | -------- |
|        |          |

ADTS ***一帧*** 数据格式（中间部分，左右省略号为前后数据帧）：

![](/img/adts.jpg)

我们熟悉的视频格式，其实是包裹了音视频编码数据的容器，用来把以特定编码标准编码的视频流和音频流混在一起，成为一个文件。

例如：mp4支持H264、H265等视频编码和AAC、MP3等音频编码。

> mp4是目前最流行的视频格式，在移动端，一般将视频封装为mp4格式。

### 硬解码和软解码

所谓软解码，就是指利用CPU的计算能力来解码，通常如果CPU的能力不是很强的时候，一则解码速度会比较慢，二则手机可能出现发热现象。但是，由于使用统一的算法，兼容性会很好。

硬解码，指的是利用手机上专门的解码芯片来加速解码。通常硬解码的解码速度会快很多，但是由于硬解码由各个厂家实现，质量参差不齐，非常容易出现兼容性问题。

# 4.播放器开发

### 流程

<img src="/img/play_step.jpg" style="zoom: 80%;" />

使用ffmpeg需要编译FFmpeg，此处就不介绍编译流程了，网上很多。编译以后导入到android项目中，然后配置好CMakeLIsts.txt文件，在Android上处理音视频的话需要OpenSLES。

**解协议**的作用，就是将流媒体协议的数据，解析为标准的相应的封装格式数据。视音频在网络上传播的时候，常常采用各种流媒体协议，例如HTTP，RTMP，或是MMS等等。这些协议在传输视音频数据的同时，也会传输一些信令数据。这些信令数据包括对播放的控制（播放，暂停，停止），或者对网络状态的描述等。解协议的过程中会去除掉信令数据而只保留视音频数据。例如，采用RTMP协议传输的数据，经过解协议操作后，输出FLV格式的数据。

**解封装**的作用，就是将输入的封装格式的数据，分离成为音频流压缩编码数据和视频流压缩编码数据。封装格式种类很多，例如MP4，MKV，RMVB，TS，FLV，AVI等等，它的作用就是将已经压缩编码的视频数据和音频数据按照一定的格式放到一起。例如，FLV格式的数据，经过解封装操作后，输出H.264编码的视频码流和AAC编码的音频码流。

**解码**的作用，就是将视频/音频压缩编码数据，解码成为非压缩的视频/音频原始数据。音频的压缩编码标准包含AAC，MP3，AC-3等等，视频的压缩编码标准则包含H.264，MPEG2，VC-1等等。解码是整个系统中最重要也是最复杂的一个环节。通过解码，压缩编码的视频数据输出成为非压缩的颜色数据，例如YUV420P，RGB等等；压缩编码的音频数据输出成为非压缩的音频抽样数据，例如PCM数据。

**视音频同步**的作用，就是根据解封装模块处理过程中获取到的参数信息，同步解码出来的视频和音频数据，并将视频音频数据送至系统的显卡和声卡播放出来。

### **封装格式**

封装格式的主要作用是把视频码流和音频码流按照一定的格式存储在一个文件中。现如今流行的封装格式如下表所示：

主要封装格式一览

| 名称 | 推出机构           | 流媒体 | 支持的视频编码                 | 支持的音频编码                        | 目前使用领域   |
| ---- | ------------------ | ------ | ------------------------------ | ------------------------------------- | -------------- |
| AVI  | Microsoft Inc.     | 不支持 | 几乎所有格式                   | 几乎所有格式                          | BT下载影视     |
| MP4  | MPEG               | 支持   | MPEG-2, MPEG-4, H.264, H.263等 | AAC, MPEG-1 Layers I, II, III, AC-3等 | 互联网视频网站 |
| TS   | MPEG               | 支持   | MPEG-1, MPEG-2, MPEG-4, H.264  | MPEG-1 Layers I, II, III, AAC,        | IPTV，数字电视 |
| FLV  | Adobe Inc.         | 支持   | Sorenson, VP6, H.264           | MP3, ADPCM, Linear PCM, AAC等         | 互联网视频网站 |
| MKV  | CoreCodec Inc.     | 支持   | 几乎所有格式                   | 几乎所有格式                          | 互联网视频网站 |
| RMVB | Real Networks Inc. | 支持   | RealVideo 8, 9, 10             | AAC, Cook Codec, RealAudio Lossless   | BT下载影视     |

由表可见，除了AVI之外，其他封装格式都支持流媒体，即可以“边下边播”。有些格式更“万能”一些，支持的视音频编码标准多一些，比如MKV。而有些格式则支持的相对比较少，比如说RMVB。