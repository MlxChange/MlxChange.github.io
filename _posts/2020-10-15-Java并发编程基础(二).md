---
layout:     post
title:      Java并发编程基础(二)
subtitle:   从基础概念到实践探索一步步理解并发
date:       2020-10-21
author:     MLX
header-img: img/android_bg.jpg
catalog: 	 true
tags:
    - Android
    - Hook
typora-root-url: ..


---

## 前言

上一篇中详细的阐述了Java 并发基础的核心部分，这一节将继续深入Java并发编程。

![](/img/并发/概览.png)

## 目录

[TOC]



## ThreadLocal

什么是ThreadLocal呢？ThreadLocal看名字就能看出来，是线程的本地。**ThreadLocal提供了线程的局部变量，每个线程都可以通过`set()`和`get()`来对这个局部变量进行操作，但不会和其他线程的局部变量进行冲突，实现了线程的数据隔离。**

简要言之：往ThreadLocal中填充的变量属于**当前**线程，该变量对其他线程而言是隔离的。

应用场景：

- 每个线程需要一个独享的对象（在Android中类似Looper对象）
- 每个线程内需要保存类似于全局变量的信息（例如在拦截器中获取用户信息，该信息在本线程执行的各方法中保持不变），可以让不同方法直接使用，却不想被多线程共享（因为不同线程获取到的用户信息不一样），避免参数传递的麻烦

### 用法

添加和获取

```java
ThreadLocal<String> mStringThreadLocal = new ThreadLocal<>();//创建ThreadLocal
mStringThreadLocal.set("mlx");//放进去一个变量
mStringThreadLocal.get();//拿出来
```

初始化值

```java
ThreadLocal<String> mThreadLocal = new ThreadLocal<String>() {   
    @Override    
    protected String initialValue() {      
    	return Thread.currentThread().getName();    
    } 
};
```

在Android中是如何使用的呢？

```java
static final ThreadLocal<Looper> sThreadLocal = new ThreadLocal<Looper>();
private static void prepare(boolean quitAllowed) {    
    if (sThreadLocal.get() != null) {        
    	throw new RuntimeException("Only one Looper may be created per thread");    
    }    
    sThreadLocal.set(new Looper(quitAllowed)); 
}
```

这样保证了一个线程中只有一个指定的Looper对象。

### 实现原理

首先看Thread对象

```java
public class Thread implements Runnable {
	ThreadLocal.ThreadLocalMap threadLocals;
}
public class ThreadLocal<T> {
    
    static class ThreadLocalMap {
            
            static class Entry extends WeakReference<ThreadLocal<?>> {
                Object value;

                Entry(ThreadLocal<?> k, Object v) {
                    super(k);
                    value = v;
                }
            }
}
```

Thread类中有一个ThreadLocal.ThreadLocalMap对象。ThreadLocalMap对象其实就是一个map对象，**key为弱引用，value为强引用**

Thread，ThreadLocal，ThreadLocalMap之间的关系是怎样的呢？

![](/img/并发/ThreadLocal原理图.png)

![](/img/并发/ThreadLocal-ref.png)

简而言之，Thread类中有一个map，这个map是ThreadLocalMap，map的Key为ThreadLocal弱引用，Value为泛型的值。

Thread类有一个map，map里有很多的ThreadLocal对象。并且是弱引用

### 关系说明

- 1个Thread有且仅有1个`ThreadLocalMap`对象；
- 1个`Entry`对象的Key弱引用指向1个`ThreadLocal`对象；
- 1个`ThreadLocalMap`对象存储多个Entry对象；
- 1个`ThreadLocal`对象可以被多个线程所共享；
- `ThreadLocal`对象不持有Value，Value由线程的Entry对象持有。

### set方法

```java
public void set(T value) {
    Thread t = Thread.currentThread();
    ThreadLocalMap map = getMap(t);
    if (map != null)
        map.set(this, value);
    else
        createMap(t, value);
}
```

`ThreadLocal`的set方法首先是拿到当前线程，然后得到当前线程的map，如果map为空就创建一个map，如果map不为空就将自己和值添加进去。

### get方法

```java
public T get() {
    Thread t = Thread.currentThread();
    ThreadLocalMap map = getMap(t);
    if (map != null) {
        ThreadLocalMap.Entry e = map.getEntry(this);
        if (e != null) {
            @SuppressWarnings("unchecked")
            T result = (T)e.value;
            return result;
        }
    }
    return setInitialValue();
}
```

`ThreadLocal`取得话就是首先拿到当前线程，然后从线程中拿到线程的map，如果map为空或者数据为空的话就调用`setInitialValue`方法，去初始化一个值。如果不为空，就将自己作为key查找对应的值。

### ThreadLocal如何做到线程安全

- 每个线程都拥有独立的`threadLocals`变量（指向`ThreadLocalMap`对象）；
- 每当线程访问`threadLocals`变量时，访问的都是各自线程自己的`ThreadLocalMap`对象；
- `ThreadLocalMap`访问的key值为当前的`ThreadLocal`实例。

### ThreadLocal的好处

- 达到线程安全
- 不需要加锁，提高执行效率

### ThreadLocal的副作用

脏数据

> 线程复用会产生脏数据。由于线程池会重用Thread对象，那么与Thread绑定的类的静态属性ThreadLocal变量也会被重用。如果在实现的线程run()方法体中不显示调用remove()清理与线程相关的ThreadLocal信息，那么倘若下一个线程不调用set()设置初始值，就可能get()到重用的线程信息，包括ThreadLocal所管理的线程对象的value值。

内存泄漏

> **由于ThreadLocalMap的生命周期跟Thread一样长，如果没有手动删除对应key就会导致内存泄漏，而不是因为弱引用**。但是key是弱引用，所以key很可能会被回收但是Value没被回收。ThreadLocal也想到了这一点，所以在remove方法中会判断如果key为null，则会让Value也设置会null。所以需要手动调用remove方法才能避免内存泄露

### 总结

最后要记住的是:**ThreadLocal设计的目的就是为了能够在当前线程中有属于自己的变量，并不是为了解决并发或者共享变量的问题**

## 线程池

线程池（Thread Pool）是一种基于池化思想管理线程的工具，经常出现在多线程服务器中

自己创建线程的弊端：线程过多会带来额外的开销，其中包括创建销毁线程的开销、调度线程的开销等等，同时也降低了计算机的整体性能。

线程池维护多个线程，等待监督管理者分配可并发执行的任务。这种做法，一方面避免了处理任务时创建销毁线程开销的代价，另一方面避免了线程数量膨胀导致的过分调度问题，保证了对内核的充分利用。

使用线程池可以带来一系列好处：

- **降低资源消耗**：通过池化技术重复利用已创建的线程，降低线程创建和销毁造成的损耗。
- **提高响应速度**：任务到达时，无需等待线程创建即可立即执行。
- **提高线程的可管理性**：线程是稀缺资源，如果无限制创建，不仅会消耗系统资源，还会因为线程的不合理分布导致资源调度失衡，降低系统的稳定性。使用线程池可以进行统一的分配、调优和监控。
- **提供更多更强大的功能**：线程池具备可拓展性，允许开发人员向其中增加更多的功能。比如延时定时线程池ScheduledThreadPoolExecutor，就允许任务延期执行或定期执行。

Java中的线程池核心实现类是ThreadPoolExecutor，它的UML图如下所示：

![](/img/并发/uml.png)

- Executor是一个顶层接口，在它里面只声明了一个方法execute(Runnable)，返回值为void，参数为Runnable类型，从字面意思可以理解，就是用来执行传进去的任务的
- `ExecutorService`接口继承了Executor接口，并声明了一些方法：submit、invokeAll、invokeAny以及shutDown等。`ExecutorService`接口增加了一些能力：
- 1. 扩充执行任务的能力，补充可以为一个或一批异步任务生成Future的方法.
- 2. 提供了管控线程池的方法，比如停止线程池的运行。
- 抽象类`AbstractExecutorService`实现了`ExecutorService`接口，基本实现了`ExecutorService`中声明的所有方法。保证下层的实现只需关注一个执行任务的方法即可。
- `ThreadPoolExecutor`继承了类`AbstractExecutorService`，并提供了一些新功能，比如获取核心线程数、获取任务队列等。`ThreadPoolExecutor`将会一方面维护自身的生命周期，另一方面同时管理线程和任务，使两者良好的结合从而执行并行任务。

### 线程池的简单使用

```java
 public static void main(String[] args) {
        // 创建一个固定大小的线程池:
        ExecutorService es = Executors.newFixedThreadPool(4);
        for (int i = 0; i < 6; i++) {
            es.submit(new Runnable{});
        }
        // 关闭线程池:
        es.shutdown();
}
```

Java标准库提供的几个常用实现类有：

- FixedThreadPool：线程数固定的线程池；
- CachedThreadPool：线程数根据任务动态调整的线程池；
- SingleThreadExecutor：仅单线程执行的线程池。
- ScheduledThreadPool  可以用来处理延时任务或者定时任务。

### 线程池的生命周期

线程池运行的状态，并不是用户显式设置的，而是伴随着线程池的运行，由内部来维护。线程池内部使用一个变量维护两个值：运行状态(runState)和线程数量 (workerCount)。在具体实现中，线程池将运行状态(runState)、线程数量 (workerCount)两个关键参数的维护放在了一起，如下代码所示：

```Java
private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));
```

`ctl`这个`AtomicInteger`类型，是对线程池的运行状态和线程池中有效线程的数量进行控制的一个字段， 它同时包含两部分的信息：线程池的运行状态 (runState) 和线程池内有效线程的数量 (workerCount)，**高3位保存runState，低29位保存workerCount**，两个变量之间互不干扰。用一个变量去存储两个值，可避免在做相关决策时，出现不一致的情况，不必为了维护两者的一致，而占用锁资源

ThreadPoolExecutor的运行状态有5种，分别为

![](/img/并发/线程池状态.png)

其生命周期转换如下入所示：

![](/img/并发/线程池状态转换.png)

### 线程池任务调度

`ThreadPoolExecutor`是核心类，这是使用方法

```java
ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, 
				   long keepAliveTime, TimeUnit unit, 
                   BlockingQueue<Runnable> workQueue, RejectedExecutionHandler handler)
```

![](/img/并发/线程池构造函数的参数.png)

什么是核心线程数和最大线程数呢？我们可以看一下线程池的调度策略

![](/img/并发/线程池调度策略.png)

当你提交一个任务给线程池的时候，线程池会首先判断核心线程是否已满，没满就创建核心线程去执行，满了的话就去添加到队列。当队列也满了的话，就会创建非核心线程去执行任务，当非核心线程达到最大线程数的时候就会执行饱和策略。

**所以线程池回收的是非核心线程，核心线程默认不会被回收掉，但是如果设置了allowCoreTimeOut为true，那么当核心线程闲置时，也会被回收。**

**初始化线程池时可以预先创建线程吗？**

初始化线程池时是可以预先创建线程的，初始化线程池后，再调用prestartAllCoreThreads()方法，即可预先创建corePoolSize数量的核心线程。

### 任务缓冲

线程池的本质是对任务和线程的管理，而做到这一点最关键的思想就是将任务和线程两者解耦，不让两者直接关联，才可以做后续的分配工作。线程池中是以生产者消费者模式，通过一个阻塞队列来实现的。阻塞队列缓存任务，工作线程从阻塞队列中获取任务

阻塞队列(BlockingQueue)是一个支持两个附加操作的队列。这两个附加的操作是：在队列为空时，获取元素的线程会等待队列变为非空。当队列满时，存储元素的线程会等待队列可用。阻塞队列常用于生产者和消费者的场景，生产者是往队列里添加元素的线程，消费者是从队列里拿元素的线程。阻塞队列就是生产者存放元素的容器，而消费者也只从容器里拿元素。

线程1往阻塞队列中添加元素，而线程2从阻塞队列中移除元素：

![](/img/并发/线程池缓冲.png)

使用不同的队列可以实现不一样的任务存取策略。在这里，我们可以再介绍下阻塞队列的成员：

主要分为

- 有界队列

  **ArrayBlockingQueue**是一个用数组实现的有界阻塞队列。此队列按照先进先出的原则对元素进行排序

  **LinkedBlockingQueue**是一个用链表实现的有界阻塞队列。此队列的默认和最大长度为`Integer.MAX_VALUE`。此队列按照先进先出的原则对元素进行排序

- 无界队列

  **PriorityBlockingQueue**是一个支持优先级的无界阻塞队列。默认情况下元素采取自然顺序升序排列。也可以自定义类实现`compareTo()`方法来指定元素排序规则，或者初始化PriorityBlockingQueue时，指定构造参数`Comparator`来进行排序

  **DelayQueue**是一个支持延时获取元素的无界阻塞队列。队列使用PriorityBlockingQueue来实现。队列中的元素必须实现Delayed接口，在创建元素时可以指定多久才能从队列中获取当前元素。只有在延迟期满时才能从队列中提取元素。

- 不存储队列

  **SynchronousQueue**是一个不存储元素的阻塞队列。每一个put操作必须等待一个take操作，否则不能继续添加元素。这个使用场景是在CachedThreadPool中就定义的是这个队列，意思就是来了任务就直接使用一个线程去执行。

### 任务拒绝

任务拒绝模块是线程池的保护部分，线程池有一个最大的容量，当线程池的任务缓存队列已满，并且线程池中的线程数目达到maximumPoolSize时，就需要拒绝掉该任务，采取任务拒绝策略，保护线程池

线程池的拒绝策略有如下四种：

- AbortPolicy:丢弃任务并抛出RejectedExecutionException异常 (默认)
- DiscardPolicy：也是丢弃任务，但是不抛出异常
- DiscardOldestPolicy：丢弃队列最前面的任务，执行后面的任务
- CallerRunsPolicy：由调用线程处理该任务 

线程重用的核心是，线程池对Thread做了包装，不重复调用Thread.start()，而是自己有一个Runnable.run()，run方法里面循环在跑，跑的过程中不断检查我们是否有新加入的子Runnable对象，有新的Runnable进来的话就调一下我们的run()，其实就一个大run()把其它小run()#1,run()#2,...给串联起来了。同一个Thread可以执行不同的Runnable，主要原因是线程池把线程和Runnable通过BlockingQueue给解耦了，线程可以从BlockingQueue中不断获取新的任务。

### Worker线程

线程池为了掌握线程的状态并维护线程的生命周期，设计了线程池内的工作线程Worker。我们来看一下它的部分代码：

```Java
private final class Worker extends AbstractQueuedSynchronizer implements Runnable{
    final Thread thread;//Worker持有的线程
    Runnable firstTask;//初始化的任务，可以为null
}
```

线程池需要管理线程的生命周期，需要在线程长时间不运行的时候进行回收。线程池使用一张Hash表去持有线程的引用，这样可以通过添加引用、移除引用这样的操作来控制线程的生命周期。这个时候重要的就是如何判断线程是否在运行。

**Worker是通过继承AQS，使用AQS来实现独占锁这个功能**。没有使用可重入锁ReentrantLock，而是使用AQS，为的就是实现不可重入的特性去反应线程现在的执行状态。

1.lock方法一旦获取了独占锁，表示当前线程正在执行任务中。 

2.如果正在执行任务，则不应该中断线程。

 3.如果该线程现在不是独占锁的状态，也就是空闲的状态，说明它没有在处理任务，这时可以对该线程进行中断。 

4.线程池在执行shutdown方法或tryTerminate方法时会调用`interruptIdleWorkers`方法来中断空闲的线程，`interruptIdleWorkers`方法会使用tryLock方法来判断线程池中的线程是否是空闲状态；如果线程是空闲状态则可以安全回收。

![](/img/并发/线程池线程回收.png)

#### worker线程回收

线程池中线程的销毁依赖JVM自动的回收，线程池做的工作是根据当前线程池的状态维护一定数量的线程引用，防止这部分线程被JVM回收，当线程池决定哪些线程需要回收时，只需要将其引用消除即可。Worker被创建出来后，就会不断地进行轮询，然后获取任务去执行，核心线程可以无限等待获取任务，非核心线程要限时获取任务。当Worker无法获取到任务，也就是获取的任务为空时，循环会结束，Worker会主动消除自身在线程池内的引用。

### 线程池的关闭

ThreadPoolExecutor提供了两个方法，用于线程池的关闭，分别是shutdown()和shutdownNow()，其中：

- shutdown()：不会立即终止线程池，而是要等所有任务缓存队列中的任务都执行完后才终止，但再也不会接受新的任务
- shutdownNow()：立即终止线程池，并尝试打断正在执行的任务，并且清空任务缓存队列，返回尚未执行的任务

### 合理配置线程池的大小

一般需要根据任务的类型来配置线程池大小：

　　如果是CPU密集型任务，就需要尽量压榨CPU，参考值可以设为 *N*CPU+1

　　如果是IO密集型任务，参考值可以设置为2**N*CPU

### 为什么阿里规范不推荐使用Executors创建线程

> 线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险

Executors 各个方法的弊端：
1）newFixedThreadPool 和 newSingleThreadExecutor:主要问题是堆积的请求处理队列可能会耗费非常大的内存，甚至 OOM。
2）newCachedThreadPool 和 newScheduledThreadPool:主要问题是线程数最大数是 Integer.MAX_VALUE，可能会创建数量非常多的线程，甚至 OOM。

## 锁

在Java并发编程中，最最绕不开的话题就是锁了。

先上一个锁的全局概览

![](/img/并发/锁.png)

可以看到在Java中有非常多的锁，根据各种不同的规则有不同的锁。

### 悲观锁和乐观锁

对于同一个数据的并发操作

**悲观锁**认为自己在使用数据的时候一定有别的线程来修改数据，因此在获取数据的时候会先加锁，确保数据不会被别的线程修改。Java中，synchronized关键字和Lock的实现类都是悲观锁

**乐观锁**认为自己在使用数据时不会有别的线程修改数据，所以不会添加锁，只是在更新数据的时候去判断之前有没有别的线程更新了这个数据。如果这个数据没有被更新，当前线程将自己修改的数据成功写入。如果数据已经被其他线程更新，则根据不同的实现方式执行不同的操作（例如报错或者自动重试）。乐观锁在Java中是通过使用无锁编程来实现，最常采用的是CAS算法，Java原子类中的递增操作就通过CAS自旋实现的。

根据从上面的概念描述我们可以发现：

- 悲观锁适合写操作多的场景，先加锁可以保证写操作时数据正确。
- 乐观锁适合读操作多的场景，不加锁的特点能够使其读操作的性能大幅提升。

```java
// ------------------------- 悲观锁的调用方式 -------------------------
// synchronized
public synchronized void testMethod() {
	// 操作同步资源
}
// ReentrantLock
private ReentrantLock lock = new ReentrantLock(); // 需要保证多个线程使用的是同一个锁
public void modifyPublicResources() {
	lock.lock();
	// 操作同步资源
	lock.unlock();
}

// ------------------------- 乐观锁的调用方式 -------------------------
private AtomicInteger atomicInteger = new AtomicInteger();  // 需要保证多个线程使用的是同一个AtomicInteger
atomicInteger.incrementAndGet(); //执行自增1
```

### 阻塞与不阻塞(自旋锁)

阻塞或唤醒一个Java线程需要操作系统切换CPU状态来完成，这种状态转换需要耗费处理器时间。如果同步代码块中的内容过于简单，状态转换消耗的时间有可能比用户代码执行的时间还要长。

在许多场景中，同步资源的锁定时间很短，为了这一小段时间去切换线程，线程挂起和恢复现场的花费可能会让系统得不偿失。

为了让当前线程“稍等一下”，我们需让当前线程进行自旋，如果在自旋完成后前面锁定同步资源的线程已经释放了锁，那么当前线程就可以不必阻塞而是直接获取同步资源，从而避免切换线程的开销。这就是自旋锁。

<img src="/img/并发/自旋锁.png" style="zoom:50%;" />

**自旋锁的实现原理同样也是CAS**，AtomicInteger中调用**unsafe**进行自增操作的源码中的do-while循环就是一个自旋操作，如果修改数值失败则通过循环来执行自旋，直至修改成功。

阻塞锁就是我们平常使用的synchronized和ReentrantLock。

**自旋锁本身是有缺点的**，它不能代替阻塞。自旋等待虽然避免了线程切换的开销，但它要占用处理器时间。如果锁被占用的时间很短，自旋等待的效果就会非常好。反之，如果锁被占用的时间很长，那么自旋的线程只会白浪费处理器资源。所以，自旋等待的时间必须要有一定的限度，如果自旋超过了限定次数（默认是10次，可以使用-XX:PreBlockSpin来更改）没有成功获得锁，就应当挂起线程。

JDK 6中引入了**自适应的自旋锁**（适应性自旋锁）

自适应意味着自旋的时间（次数）不再固定，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也是很有可能再次成功，进而它将允许自旋等待持续相对更长的时间。如果对于某个锁，自旋很少成功获得过，那在以后尝试获取这个锁时将可能省略掉自旋过程，直接阻塞线程，避免浪费处理器资源。

### 无锁 VS 偏向锁 VS 轻量级锁 VS 重量级锁

这四种锁是指锁的状态，专门针对synchronized的

为什么Synchronized能实现线程同步？我们需要了解两个重要的概念：“Java对象头”、“Monitor”。

#### Java对象头

synchronized是悲观锁，在操作同步资源之前需要给同步资源先加锁，这把锁就是存在Java对象头里的，而Java对象头又是什么呢？

我们以Hotspot虚拟机为例，Hotspot的对象头主要包括两部分数据：Mark Word（标记字段）、Klass Pointer（类型指针）。

**Mark Word**：默认存储对象的HashCode，分代年龄和锁标志位信息。这些信息都是与对象自身定义无关的数据，所以Mark Word被设计成一个非固定的数据结构以便在极小的空间内存存储尽量多的数据。它会根据对象的状态复用自己的存储空间，也就是说在运行期间Mark Word里存储的数据会随着锁标志位的变化而变化。

**Klass Point**：对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。

#### Monitor

Monitor可以理解为一个同步工具或一种同步机制，通常被描述为一个对象。每一个Java对象就有一把看不见的锁，称为内部锁或者Monitor锁。

Monitor是**线程私有**的数据结构，每一个线程都有一个可用monitor record列表，同时还有一个全局的可用列表。每一个被锁住的对象都会和一个monitor关联，同时monitor中有一个Owner字段存放拥有该锁的线程的唯一标识，表示该锁被这个线程占用。

**synchronized通过Monitor来实现线程同步，Monitor是依赖于底层的操作系统的Mutex Lock（互斥锁）来实现的线程同步**

这种依赖于操作系统Mutex Lock所实现的锁我们称之为“重量级锁”，JDK 6中为了减少获得锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁”。

目前锁一共有4种状态，级别从低到高依次是：无锁、偏向锁、轻量级锁和重量级锁。锁状态只能升级不能降级

四种锁状态对应的的Mark Word内容

| 锁状态   | 存储内容                                                | 存储内容 |
| :------- | :------------------------------------------------------ | :------- |
| 无锁     | 对象的hashCode、对象分代年龄、是否是偏向锁（0）         | 01       |
| 偏向锁   | 偏向线程ID、偏向时间戳、对象分代年龄、是否是偏向锁（1） | 01       |
| 轻量级锁 | 指向栈中锁记录的指针                                    | 00       |
| 重量级锁 | 指向互斥量（重量级锁）的指针                            | 10       |

#### 偏向锁

偏向锁是指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁，降低获取锁的代价。

一个锁对象并不会发生被多个线程访问得情况，更多是被**同一个线程**进行访问，如果一个锁对象每次都被同一个线程访问，根本没有发生并发，但是每次都进行加锁，那岂不是非常耗费性能，所以偏向锁就被设计出来了

当一个线程访问同步块并获取锁时，会在**对象头**和**栈帧中的锁记录**里存储锁偏向的线程ID，以后该线程在进入和退出同步块时不需要进行CAS操作来加锁和解锁，只需简单地测试一下对象头的Mark Word里是否存储着指向当前线程的偏向锁

如果测试成功，表示线程已经获得了锁；如果测试失败，则需要再测试一下Mark Word中偏向锁的标识是否设置成1（表示当前是偏向锁）：如果没有设置，则使用CAS竞争锁；如果设置了，则尝试使用CAS将对象头的偏向锁指向当前线程（线程ID）；

但是这中间只要发生了其他线程访问该锁对象的情况，证明这个锁对象会发生并发，就不能对这个对象再使用偏向锁了，会进行锁的升级

#### 轻量级锁

当有竞争且竞争不强烈时，JVM就会由偏向锁膨胀为轻量级锁，考虑到线程的阻塞和唤醒需要CPU从用户态转为核心态（增加CPU负担），而这种转换对CPU来说是一件负担很重的操作，因此没有获取到锁的线程不会进入阻塞状态，而是通过自旋的方式一直尝试获取锁，处于一种忙等状态，所以这种处理竞争的方式比较浪费CPU，但是响应速度很快

#### 重量级锁

升级为重量级锁时，锁标志的状态值变为“10”，此时Mark Word中存储的是指向重量级锁的指针，此时等待锁的线程不会立刻进入阻塞状态而是会自旋一段时间看是否能获取锁如果不能则进入阻塞状态。

### 公平锁和非公平锁

**公平锁**是指多个线程按照申请锁的顺序来获取锁，线程直接进入队列中排队，队列中的第一个线程才能获得锁。公平锁的优点是等待锁的线程不会饿死。缺点是整体吞吐效率相对非公平锁要低，等待队列中除第一个线程以外的所有线程都会阻塞，CPU唤醒阻塞线程的开销比非公平锁大。

**非公平锁**是多个线程加锁时直接尝试获取锁，获取不到才会到等待队列的队尾等待。但如果此时锁刚好可用，那么这个线程可以无需阻塞直接获取到锁，所以非公平锁有可能出现后申请锁的线程先获取锁的场景。非公平锁的优点是可以减少唤起线程的开销，整体的吞吐效率高，因为线程有几率不阻塞直接获得锁，CPU不必唤醒所有线程。缺点是处于等待队列中的线程可能会饿死，或者等很久才会获得锁

![](/img/并发/公平锁非公平锁优缺点.png)

公平锁就是通过同步队列来实现多个线程按照申请锁的顺序来获取锁，从而实现公平的特性。非公平锁加锁时不考虑排队等待问题，直接尝试获取锁（通过CAS的方式获取，就是A释放，唤醒B的过程中，C正好过来然后修改了state，B发现没锁了继续阻塞），所以存在后申请却先获得锁的情况。

### 可重入锁 和 非可重入锁

**可重入锁又名递归锁**，是指在同一个线程在外层方法获取锁的时候，再进入该线程的内层方法会自动获取锁（前提锁对象得是同一个对象或者class），不会因为之前已经获取过还没释放而阻塞。Java中ReentrantLock和synchronized都是可重入锁，可重入锁的一个优点是可一定程度避免死锁

```java
public class Widget {
    public synchronized void doSomething() {
        System.out.println("方法1执行...");
        doOthers();
    }

    public synchronized void doOthers() {
        System.out.println("方法2执行...");
    }
}
```

类中的两个方法都是被内置锁synchronized修饰的，doSomething()方法中调用doOthers()方法。因为内置锁是可重入的，所以同一个线程在调用doOthers()时可以直接获得当前对象的锁，进入doOthers()进行操作

如果是一个不可重入锁，那么当前线程在调用doOthers()之前需要将执行doSomething()时获取当前对象的锁释放掉，实际上该对象锁已被当前线程所持有，且无法释放。所以此时会出现死锁

ReentrantLock中是有一个sync继承了AQS的，使用state来记数。

**当线程尝试获取锁**时，可重入锁先尝试获取并更新status值，如果status == 0表示没有其他线程在执行同步代码，则把status置为1，当前线程开始执行。如果status != 0，则判断当前线程是否是获取到这个锁的线程，如果是的话执行status+1，且当前线程可以再次获取锁。

而**非可重入锁**是直接去获取并尝试更新当前status的值，如果status != 0的话会导致其获取锁失败，当前线程阻塞

**释放锁时**，可重入锁同样先获取当前status的值，在当前线程是持有锁的线程的前提下。如果status-1 == 0，则表示当前线程所有重复获取锁的操作都已经执行完毕，然后该线程才会真正释放锁。而非可重入锁则是在确定当前线程是持有锁的线程之后，直接将status置为0，将锁释放

###  独享锁 VS 共享锁

**独享锁**也叫排他锁，是指**该锁一次只能被一个线程所持有**。如果线程T对数据A加上排它锁后，则其他线程不能再对A加任何类型的锁。获得排它锁的线程既能读数据又能修改数据。JDK中的`synchronized`和JUC中Lock的实现类就是互斥锁

**共享锁**是指该锁可被多个线程所持有。如果线程T对数据A加上共享锁后，则其他线程只能对A再加共享锁，不能加排它锁。获得共享锁的线程**只能读数据，不能修改数据。**比如`ReentrantReadWriteLock`

### JVM对锁的优化

自旋锁、自适应自旋锁、锁粗化、锁消除、偏向锁、轻量级锁。

自适应自旋锁上面讲完了

#### 锁粗化

如果在一段代码中同一线程反复获取、释放同一个对象的锁，将会生产不必要的性能开销，所以需要把获锁的范围扩大，对同一个对象的锁操作只进行一次，在头部获取锁，在尾部释放锁

#### 锁消除

锁消除是发生在编译器级别的一种锁优化方式。

锁消除是指JIT在运行时分析到使用了锁的同步代码在实际运行时不可能存在共享数据被竞争的情况，对锁进行去除。例如如果一个局部变量在方法内部不可能被外部引用，那么它就不需要加锁控制，可以去掉锁。

锁消除，前提是java必须运行在server模式（server模式会比client模式作更多的优化），同时必须开启逃逸分析

### 我们应该如何使用锁

- 缩小同步代码块，只锁必要的操作数据的部分，把其他不相关的、开销大的、可能被阻塞的操作，例如IO操作，通通移出互斥的范围
- 尽量不要锁住方法
- 减少请求锁的请求次数
- 锁中尽量不要再包含锁，否则很容易死锁

## 并发集合

- ConcurrentHashMap：线程安全的HashMap
- CopyOnWriteArrayList: 线程安全的List
- BlockingQueue: 这是一个接口，表示阻塞队列，非常适合用于作为数据共享的通道。
- ConcurrentLinkedQueue：高效的非阻塞并发队列，使用链表实现。可以看做一个线程安全的LinkedList。
- ConcurrentSkipListMap: 是一个Map，使用跳表的数据结构进行快速查找。

### 古老的并发容器

Vector和Hashtable实现线程安全的方式就是最简单的所有操作都加锁，这样性能很差劲。所以被抛弃了

ArrayList和HashMap虽然这两个类不是线程安全的，但是可以用Collections.synchronizedList(new ArrayList<E>())和Collections.synchronizedMap(new HashMap<K, V>())使之变成线程安全的。其实本质上也还是对操作全部加锁。

### 新时代的并发容器

#### ConcurrentHashMap

ConcurrentHashMap 底层是基于 `数组 + 链表` 组成的，不过在 jdk1.7 和 1.8 中具体实现稍有不同。

##### 1.7中的数据结构

![](/img/并发/hashmap17.png)

如图所示，是由 Segment 数组、HashEntry 组成，和 HashMap 一样，仍然是**数组加链表**。

Segment 是 ConcurrentHashMap 的一个内部类.

ConcurrentHashMap 采用了**分段锁**技术，其中 Segment 继承于 ReentrantLock。

不会像 HashTable 那样不管是 put 还是 get 操作都需要做同步处理，理论上 ConcurrentHashMap 支持 CurrencyLevel (Segment 数组数量)的线程并发。

每当一个线程占用锁访问一个 Segment 时，不会影响到其他的 Segment。就是说如果容量大小是16他的并发度就是16，可以同时允许16个线程操作16个Segment而且还是线程安全的

**put具体操作**

1. 尝试自旋获取锁。
2. 如果重试的次数达到了 `MAX_SCAN_RETRIES` 则改为阻塞锁获取，保证能获取成功。

**get操作**

只需要将 Key 通过 Hash 之后定位到具体的 Segment ，再通过一次 Hash 定位到具体的元素上。由于 HashEntry 中的 value 属性是用 volatile 关键词修饰的，保证了内存可见性，所以每次获取时都是最新值。

ConcurrentHashMap 的 get 方法是非常高效的，**因为整个过程都不需要加锁**

##### 1.8中的数据结构

抛弃了原有的 Segment 分段锁，而采用了 `CAS + synchronized` 来保证并发安全性.

跟HashMap很像，也把之前的HashEntry改成了Node，但是作用不变，把值和next采用了volatile去修饰，保证了可见性，并且也引入了红黑树，在链表大于一定值的时候会转换（默认是8）

**put操作**

ConcurrentHashMap在进行put操作的还是比较复杂的，大致可以分为以下步骤：

1. 根据 key 计算出 hashcode 。
2. 判断是否需要进行初始化。
3. 即为当前 key 定位出的 Node，如果为空表示当前位置可以写入数据，利用 CAS 尝试写入，失败则自旋保证成功。
4. 如果当前位置的 `hashcode == MOVED == -1`,则需要进行扩容。
5. 如果都不满足，则利用 synchronized 锁写入数据。
6. 如果数量大于 `TREEIFY_THRESHOLD` 则要转换为红黑树

**get操作**

- 根据计算出来的 hashcode 寻址，如果就在桶上那么直接返回值。
- 如果是红黑树那就按照树的方式获取值。
- 就不满足那就按照链表的方式遍历获取值。

##### 为什么要修改数据结构呢

1.7去查询的时候，还得遍历链表，会导致效率很低，这个跟jdk1.7的HashMap是存在的一样问题

##### 为什么HashMap是线程不安全的

1.多线程同时碰撞导致数据丢失

2.多线程同时put扩容会导致数据丢失

3.会发生CPU 死循环导致100%的问题(主要是环形链表导致的问题，仅在jdk1.7之前存在)

#### CopyOnWriteArrayList	

出现的原因：Vector和SynchronizedList的锁的粒度太大，并发效率相对比较低，并且迭代时无法编辑

##### fail-fast

**快速失败（fail—fast）**是java集合中的一种机制， 在用迭代器遍历一个集合对象时，如果遍历过程中对集合对象的内容进行了修改（增加、删除、修改），则会抛出Concurrent Modification Exception。

迭代器在遍历时直接访问集合中的内容，并且在遍历过程中使用一个 modCount 变量。

集合在被遍历期间如果内容发生变化，就会改变modCount的值。

每当迭代器使用hashNext()/next()遍历下一个元素之前，都会检测modCount变量是否为expectedmodCount值，是的话就返回遍历；否则抛出异常，终止遍历。

##### Copy-On-Write

`Copy-On-Write`，顾名思义，在计算机中就是当你想要对一块内存进行修改时，我们不在原有内存块中进行`写`操作，而是将内存拷贝一份，在新的内存中进行`写`操作，`写`完之后呢，就将指向原来内存指针指向新的内存，原来的内存就可以被回收掉嘛！

Copy-On-Write简称COW，是一种用于程序设计中的优化策略。从一开始大家都在共享同一个内容，当某个人想要修改这个内容的时候，才会真正把内容Copy出去形成一个新的内容然后再改，这是一种延时懒惰策略

**CopyOnWrite容器即写时复制的容器**。通俗的理解是当我们往一个容器添加元素的时候，不直接往当前容器添加，而是先将当前容器进行Copy，复制出一个新的容器，然后新的容器里添加元素，添加完元素之后，再将原容器的引用指向新的容器。

**CopyOnWriteArrayList中add/remove等写方法是需要加锁的**，目的是为了避免Copy出N个副本出来，导致并发写。

但是，**CopyOnWriteArrayList中的读方法是没有加锁的。**

CopyOnWriteArrayList是线程安全容器(相对于ArrayList)，底层通过**复制数组**的方式来实现

CopyOnWriteArrayList在遍历的使用不会抛出ConcurrentModificationException异常，并且遍历的时候就不用额外加锁

##### add

```java
public boolean add(E e) {
        final ReentrantLock lock = this.lock;//重入锁
        lock.lock();//加锁啦
        try {
            Object[] elements = getArray();
            int len = elements.length;
            Object[] newElements = Arrays.copyOf(elements, len + 1);//拷贝新数组
            newElements[len] = e;
            setArray(newElements);//将引用指向新数组  1
            return true;
        } finally {
            lock.unlock();//解锁啦
        }
}
```

`add()`在添加集合的时候加上了锁，保证了同步，避免了多线程写的时候会Copy出N个副本出来。**复制一个新数组，增加操作在新数组上完成，将array指向到新数组中**，最后解锁。

##### get

```java
public E get(int index) {
    return get(getArray(), index);
}
```

**CopyOnWriteArrayList中的get方法是没有加锁的。**

##### 优点

- 数据一致性完整，为什么？因为加锁了，并发数据不会乱
- 解决了`像ArrayList`、`Vector`这种集合多线程遍历迭代问题，记住，`Vector`虽然线程安全，只不过是加了`synchronized`关键字，迭代问题完全没有解决！

##### 缺点

- 因为CopyOnWrite的写是复制机制，所以在进行写操作的时候，内存里会同时驻扎两个对象的内存。
- CopyOnWrite容器只能保证数据的最终一致性，不能保证数据的实时一致性。所以如果你希望写入的的数据，马上能读到，请不要使用CopyOnWrite容器。

##### 适用场景

读操作可以尽可能地快，而写即使慢一些也没有太大关系

读多写少

## CAS

乐观锁的实现原理就是CAS。

CAS全称 Compare And Swap（比较与交换），是一种无锁算法。在不使用锁（没有线程被阻塞）的情况下实现多线程之间的变量同步。java.util.concurrent包中的原子类就是通过CAS来实现了乐观锁。

CAS 的思想很简单：**三个参数，一个当前内存值 V、旧的预期值 A、即将更新的值 B，当且仅当预期值 A 和内存值 V 相同时，将内存值修改为 B 并返回 true，否则什么都不做，并返回 false**。

![](/img/并发/cas.png)

CAS底层是调用的unsafe类的Native方法来实现的。

Unsafe是CAS的核心类。Java无法直接访问底层操作系统，而是通过本地（native）方法来访问。不过尽管如此，JVM还是开了一个后门，JDK中有一个类Unsafe，它提供了硬件级别的原子操作。

value是用volatile修饰的，保证了多线程之间看到的value值是同一份。

Unsafe类中的compareAndSwapInt方法，方法中先想拿到变量value在内存中的地址。通过Atomic::cmpxchg实现原子性的比较和替换，其中参数x是即将更新的值，参数e是原内存的值。至此，最终完成了CAS的全过程。

#### 应用场景

乐观锁  并发容器以及原子类

#### 问题

##### ABA问题

如果一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时会发现它的值没有发生变化，但是实际上却变化了。这就是CAS的ABA问题。 常见的解决思路是使用版本号。在变量前面追加上版本号，每次变量更新的时候把版本号加一，那么`A-B-A` 就会变成`1A-2B-3A`。

目前在JDK的atomic包里提供了一个类`AtomicStampedReference`来解决ABA问题

##### 自旋问题

如果 CAS 一直操作不成功，会造成长时间原地自旋，会给 CPU 带来非常大的执行开销

##### 只能保证一个共享变量的原子操作

对一个共享变量执行操作时，CAS能够保证原子操作，但是对多个共享变量操作时，CAS是无法保证操作的原子性的。

- Java从1.5开始JDK提供了AtomicReference类来保证引用对象之间的原子性，可以把多个变量放在一个对象里来进行CAS操作

## 控制并发流程

### 倒计时器CountDownLatch

在多线程协作完成业务功能时，有时候需要等待其他多个线程完成任务之后，主线程才能继续往下执行业务功能，在这种的业务场景下，通常可以使用 Thread 类的 join 方法，让主线程等待被 join 的线程执行完之后，主线程才能继续往下执行。

java 并发工具类中为我们提供了类似“倒计时”这样的工具类，可以十分方便的完成所说的这种业务场景

CountDownLatch 的构造方法看起：

```
public CountDownLatch(int count)
```

构造方法会传入一个整型数 N，之后调用 CountDownLatch 的`countDown`方法会对 N 减一，知道 N 减到 0 的时候，当前调用`await`方法的线程继续执行。

CountDownLatch 的方法

1. await()：调用该方法的线程等到构造方法传入的 N 减到 0 的时候，才能继续往下执行；
2. await(long timeout, TimeUnit unit)：与上面的 await 方法功能一致，只不过这里有了时间限制，调用该方法的线程等到指定的 timeout 时间后，不管 N 是否减至为 0，都会继续往下执行；
3. countDown()：使 CountDownLatch 初始值 N 减 1；
4. long getCount()：获取当前 CountDownLatch 维护的值；

### Semaphore信号量

信号量的作用是维护一个“许可证”的计数，线程可以“获取”许可证，那信号量剩余的许可证就减一，线程也可以“是否”一个许可证，那信号量剩余的许可证就加一，当信号量所拥有的许可证数量为0，那么下一个还想要获取许可证的线程，就需要等待，直到有另外的线程释放了许可证。

可以通过构造函数来指定为公平锁还是非公平锁，公平的意思这个许可只会给按先来后到的顺序给等待队列中的线程。而非公平的意思就是对于任何申请许可的线程，都第一时间看是否有多余的许可，如果有则给此线程。

- 正常情况下获取许可证
- 没许可证时，会阻塞前来请求的线程
- 有线程释放信号量后

#### 主要方法

acquire() /  release()

tryAcquire() / tryAcquire(timeout)

注意点：

1. 获取和释放的许可证数量必须一致，否则比如每次都获取2个但是只释放1个甚至不释放，随着时间的推移，到最后许可证数量不够用，会导致程序卡死。（虽然信号量类并不对是否和获取的数量做规定，但是这是我们的编程规范，否则容易出错）

2. 注意在初始化Semaphore的时候设置公平性，一般设置为true会更合理

3. 并不是必须由获取许可证的线程释放那个许可证，事实上，获取和释放许可证对线程并无要求，也许是A获取了，然后由B释放，只要逻辑合理即可。
4. 信号量的作用，除了控制临界区最多同时有N个线程访问外，另一个作用是可以实现“条件等待”，例如线程1需要在线程2完成准备工作后才能开始工作，那么就线程1acquire()，而线程2完成任务后release()，这样的话，相当于是轻量级的CountDownLatch。

5. 可以跨线程/跨线程池共享同一个信号量。

### CyclicBarrier循环栅栏

可以实现让一组线程等待至某个状态之后再全部同时执行。CyclicBarrier可以被重用

CyclicBarrier类位于java.util.concurrent包下，CyclicBarrier提供2个构造器：

```
public CyclicBarrier(int parties, Runnable barrierAction) {
}
 
public CyclicBarrier(int parties) {
}
```

参数parties指让多少个线程或者任务等待至barrier状态；参数barrierAction为当这些线程都达到barrier状态时会执行的内容。

CyclicBarrier中最重要的方法就是await方法，它有2个重载版本

```
public int await() throws InterruptedException, BrokenBarrierException { };
public int await(long timeout, TimeUnit unit)throws InterruptedException,BrokenBarrierException,TimeoutException { };
```

#### 与CountDownLatch的区别

- 首先二者都能让一个或多个线程阻塞等待，都可以用在多个线程间的协调，起到线程同步的作用。但CountDownLatch是多个线程都进行了countDown之后才会触发时间，唤醒await在latch上的线程，执行完countDown操作之后会继续自己线程的工作，是针对事件的。而CyclicBarrier是一个栅栏，用于同步所有调用await方法的线程，等到所有的方法都执行了await方法后，所有的线程才会返回各自执行自己的工作。是针对线程的。
- CountDownLatch计数器只能使用一次，而CyclicBarrier的计数器可以调用 reset() 方法重置，能处理更加复杂的业务场景。



## AQS

Java中的大部分同步类（Lock、Semaphore、ReentrantLock等）都是基于AbstractQueuedSynchronizer（简称为AQS）实现的

AQS是一种提供了原子式管理同步状态、阻塞和唤醒线程功能以及队列模型的简单框架